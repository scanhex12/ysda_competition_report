# Отчет по соревнованию ML-1

### 0. Как побить бейзлайн

- Увеличиваем число итераций в lightgbm до 550

Также пробовал разделить данные и сделать бэггинг (```n_estimators = 3```) - работает хуже (вообще если разделять данные и последовательно подавать модели новую пачку, дообучая ее, то это работает значительно хуже)

### 1. Внедряем SVD
1. Получаем эмбеддинги users и requests с помощью svd (ноутбук svd_embeddings)
2. Добавляем полученные эмбеддинги как фичи для baseline

### 2. Делаем эмбеддинги поумнее - пишем DSSM

Обучение dssm лежит в файлике dssm_training.ipynb

Не уверен, что модель что-то выучила, потому что из-за огромного числа данных лосс не очень падает:

![image](https://user-images.githubusercontent.com/75157521/204125101-3b91147e-e4f7-4ee4-a19d-2d348978d1e4.png)

### 3. Добавляем lightfm

Обучаем на истории lightfm и добавляем его предсказания как фичу в модель

### 4. Обучаем ALS

### 5. Попробуем кластеризовать эмбеддинги dssm

### 6. Попробуем кластеризовать эмбеддинги svd
